{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "constitutional-belarus",
   "metadata": {},
   "source": [
    "# How to Improve Class Imbalance using Class Weights in Machine Learning\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2020/10/improve-class-imbalance-class-weights/\n",
    "\n",
    "https://www.kaggle.com/swatis1/stroke-prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mature-cover",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "https://www.jeremyjordan.me/imbalanced-data/\n",
    "\n",
    "[imbalance in trees+good pics for other slides](https://amueller.github.io/aml/05-advanced-topics/11-imbalanced-datasets.html)\n",
    "\n",
    "A classification problem in machine learning is where we have given some input (independent variables), and we have to predict a discrete target. It is highly possible that the distribution of discrete values will be very different. Due to this difference in each class, the algorithms tend to get biased towards the majority values present and don’t perform well on the minority values.\n",
    "\n",
    "This difference in class frequencies affects the overall predictability of the model.\n",
    "\n",
    "Getting good accuracy on these problems is not very difficult, but it is not always about getting a good score. We need to check whether the performance of these models makes any business sense or have any value. That is why it is essential to understand your problem statement and data so that you could use the right metric and optimize it using suitable methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifth-black",
   "metadata": {},
   "source": [
    "## What is Class Imbalance?\n",
    "\n",
    "Class imbalance is a problem that occurs in machine learning classification problems. It merely tells that the target class’s frequency is highly imbalanced, i.e., the occurrence of one of the classes is very high compared to the other classes present. In other words, there is a bias or skewness towards the majority class present in the target. Suppose we consider a binary classification where the majority target class has 10000 rows, and the minority target class has only 100 rows. In that case, the ratio is 100:1, i.e., for every 100 majority class, there is only one minority class present. This problem is what we refer to as class imbalance. Some of the general areas where we can find such data are fraud detection, churn prediction, medical diagnosis, e-mail classification, etc.\n",
    "\n",
    "We will be working on a dataset from the medical domain to understand class imbalance properly. Here, we have to predict whether a person will have a heart stroke or not based on the given attributes(independent variables). To skip the cleaning and the preprocessing of the data, we are using the cleaned version of the data.\n",
    "\n",
    "In the below image, you can see the distribution of our target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "constitutional-employer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "cooperative-klein",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./dataset/train_strokes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "final-professor",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mgh/anaconda3/envs/py37/lib/python3.7/site-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Percentage of patients will/will not have heart stroke')"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Ploting barplot for target \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(10,6))\n",
    "g = sns.barplot(data['stroke'], data['stroke'], palette='Set1', estimator=lambda x: len(x) / len(data) )\n",
    "\n",
    "#Anotating the graph\n",
    "for p in g.patches:\n",
    "        width, height = p.get_width(), p.get_height()\n",
    "        x, y = p.get_xy() \n",
    "        g.text(x+width/2, \n",
    "               y+height, \n",
    "               '{:.0%}'.format(height), \n",
    "               horizontalalignment='center',fontsize=15)\n",
    "\n",
    "#Setting the labels\n",
    "plt.xlabel('Heart Stroke', fontsize=14)\n",
    "plt.ylabel('Precentage', fontsize=14)\n",
    "plt.title('Percentage of patients will/will not have heart stroke', fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ruled-humor",
   "metadata": {},
   "source": [
    "Here,\n",
    "\n",
    "* 0: signifies that the patient didn’t have a heart stroke.\n",
    "\n",
    "* 1: signifies that the patient had a heart stroke.\n",
    "\n",
    "From the distribution, we can see that there are only 2% of patients who had a heart stroke. So, this is a classic class imbalance problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "molecular-pierre",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    42617\n",
       "1      783\n",
       "Name: stroke, dtype: int64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['stroke'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mounted-revolution",
   "metadata": {},
   "source": [
    "## Why is it essential to deal with class imbalance?\n",
    "\n",
    "So far, we got the intuition about class imbalance. But why is it necessary to overcome this, and what problems does it create while modeling with such data?\n",
    "\n",
    "Most machine learning algorithms assume that the data is evenly distributed within classes. In the case of class imbalance problems, the extensive issue is that the algorithm will be more biased towards predicting the majority class (no heart stroke in our case). The algorithm will not have enough data to learn the patterns present in the minority class (heart stroke).\n",
    "\n",
    "Let’s take a real-life example to understand this better.\n",
    "\n",
    "Consider you have shifted from your hometown to a new city and you been living here for the past month. When it comes to your hometown, you will be very familiar with all the locations like your home, routes, essential shops, tourist spots, etc. because you had spent your whole childhood there. But when it comes to the new city, you would not have many ideas about where each location exactly is, and the chances of taking the wrong routes and getting lost will be very high. Here, your hometown is your majority class, and the new city is the minority class.\n",
    "\n",
    "Similarly, this happens in class imbalance. The model has adequate information about the majority class but insufficient information about your minority class. That is why there will be high misclassification errors for the minority class.\n",
    "\n",
    "**Note:** *To check the performance of the model, we will be using the f1 score as the metric, not accuracy.*\n",
    "\n",
    "The reason is if we create a dumb model that predicts every new training data as 0 (no heart stroke) even then we will get very high accuracy because the model is biased towards the majority class. Here, the model is heavily accurate but not at all serving any value to our problem statement. That is why we will be using f1 score as the evaluation metric. F1 score is nothing but the harmonic mean of precision and recall. However, the evaluation metric is chosen based on the business problem and what type of error we want to reduce. But, the f1 score is the go-to metric when it comes to class imbalance problems.\n",
    "\n",
    "Here’s the formula for f1-score:\n",
    "\n",
    "$$\n",
    "\\text{f1-score} = \\frac{2(\\text{precision*recall})}{(\\text{precision+recall})}\n",
    "$$\n",
    "\n",
    "Let’s confirm this by training a model based on the model of the target variable on our heart stroke data and check what scores we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "numeric-pregnancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#performing label encoding for the dataset\n",
    "from sklearn import preprocessing \n",
    "\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "for col in data.columns:\n",
    "    if isinstance(data[col][1], str):\n",
    "            data[col] = encoder.fit_transform(data[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "processed-import",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30669</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>95.12</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30468</td>\n",
       "      <td>1</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>87.96</td>\n",
       "      <td>39.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16523</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>110.89</td>\n",
       "      <td>17.6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56543</td>\n",
       "      <td>0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>69.04</td>\n",
       "      <td>35.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46136</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>161.28</td>\n",
       "      <td>19.1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>32257</td>\n",
       "      <td>0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>210.95</td>\n",
       "      <td>50.1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>52800</td>\n",
       "      <td>0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>77.59</td>\n",
       "      <td>17.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>41413</td>\n",
       "      <td>0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>243.53</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15266</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>77.67</td>\n",
       "      <td>32.3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>28674</td>\n",
       "      <td>0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>205.84</td>\n",
       "      <td>54.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  gender   age  hypertension  heart_disease  ever_married  work_type  \\\n",
       "0  30669       1   3.0             0              0             0          4   \n",
       "1  30468       1  58.0             1              0             1          2   \n",
       "2  16523       0   8.0             0              0             0          2   \n",
       "3  56543       0  70.0             0              0             1          2   \n",
       "4  46136       1  14.0             0              0             0          1   \n",
       "5  32257       0  47.0             0              0             1          2   \n",
       "6  52800       0  52.0             0              0             1          2   \n",
       "7  41413       0  75.0             0              1             1          3   \n",
       "8  15266       0  32.0             0              0             1          2   \n",
       "9  28674       0  74.0             1              0             1          3   \n",
       "\n",
       "   Residence_type  avg_glucose_level   bmi  smoking_status  stroke  \n",
       "0               0              95.12  18.0               3       0  \n",
       "1               1              87.96  39.2               1       0  \n",
       "2               1             110.89  17.6               3       0  \n",
       "3               0              69.04  35.9               0       0  \n",
       "4               0             161.28  19.1               3       0  \n",
       "5               1             210.95  50.1               3       0  \n",
       "6               1              77.59  17.7               0       0  \n",
       "7               0             243.53  27.0               1       0  \n",
       "8               0              77.67  32.3               2       0  \n",
       "9               1             205.84  54.6               1       0  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "acoustic-librarian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>51676</td>\n",
       "      <td>0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>202.21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>31091</td>\n",
       "      <td>1</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>106.23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>54312</td>\n",
       "      <td>0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>209.58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>11999</td>\n",
       "      <td>0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>79.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>22470</td>\n",
       "      <td>1</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>184.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43317</th>\n",
       "      <td>2558</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>72.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43339</th>\n",
       "      <td>10463</td>\n",
       "      <td>0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>100.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43351</th>\n",
       "      <td>7580</td>\n",
       "      <td>0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>99.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43371</th>\n",
       "      <td>18119</td>\n",
       "      <td>0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>182.45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43388</th>\n",
       "      <td>31321</td>\n",
       "      <td>0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>228.43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1462 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  gender   age  hypertension  heart_disease  ever_married  \\\n",
       "81     51676       0  61.0             0              0             1   \n",
       "95     31091       1  34.0             0              1             1   \n",
       "113    54312       0  76.0             1              0             1   \n",
       "186    11999       0  63.0             0              0             1   \n",
       "231    22470       1  61.0             0              0             1   \n",
       "...      ...     ...   ...           ...            ...           ...   \n",
       "43317   2558       0  62.0             0              1             1   \n",
       "43339  10463       0  76.0             0              0             0   \n",
       "43351   7580       0  58.0             1              0             1   \n",
       "43371  18119       0  78.0             0              0             1   \n",
       "43388  31321       0  64.0             1              0             1   \n",
       "\n",
       "       work_type  Residence_type  avg_glucose_level  bmi  smoking_status  \\\n",
       "81             3               0             202.21  NaN               1   \n",
       "95             2               1             106.23  NaN               0   \n",
       "113            3               1             209.58  NaN               1   \n",
       "186            0               0              79.92  NaN               2   \n",
       "231            0               1             184.15  NaN               3   \n",
       "...          ...             ...                ...  ...             ...   \n",
       "43317          0               1              72.29  NaN               1   \n",
       "43339          2               0             100.55  NaN               1   \n",
       "43351          2               1              99.29  NaN               3   \n",
       "43371          2               1             182.45  NaN               0   \n",
       "43388          0               0             228.43  NaN               2   \n",
       "\n",
       "       stroke  \n",
       "81          1  \n",
       "95          0  \n",
       "113         0  \n",
       "186         0  \n",
       "231         0  \n",
       "...       ...  \n",
       "43317       0  \n",
       "43339       1  \n",
       "43351       0  \n",
       "43371       0  \n",
       "43388       0  \n",
       "\n",
       "[1462 rows x 12 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_NaN = data.isnull()\n",
    "row_has_NaN = is_NaN.any(axis=1)\n",
    "rows_with_NaN = data[row_has_NaN]\n",
    "rows_with_NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "sustainable-praise",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in data.columns:\n",
    "    data[col].fillna(data[col].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "dominican-spice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, gender, age, hypertension, heart_disease, ever_married, work_type, Residence_type, avg_glucose_level, bmi, smoking_status, stroke]\n",
       "Index: []"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_NaN = data.isnull()\n",
    "row_has_NaN = is_NaN.any(axis=1)\n",
    "rows_with_NaN = data[row_has_NaN]\n",
    "rows_with_NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "revised-animation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43400, 11)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dropping the output label\n",
    "X= data.drop('stroke', axis=1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "respiratory-parade",
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardizing the dataset with Standard Scaler\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "  \n",
    "scalar = StandardScaler() \n",
    "  \n",
    "for col in X.columns:\n",
    "    X[[col]] = scalar.fit_transform(X[[col]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "marked-bottle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.268469</td>\n",
       "      <td>1.201081</td>\n",
       "      <td>-1.741517</td>\n",
       "      <td>-0.321296</td>\n",
       "      <td>-0.223342</td>\n",
       "      <td>-1.344203</td>\n",
       "      <td>1.659945</td>\n",
       "      <td>-1.002584</td>\n",
       "      <td>-0.217176</td>\n",
       "      <td>-1.384161</td>\n",
       "      <td>1.286407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.278007</td>\n",
       "      <td>1.201081</td>\n",
       "      <td>0.700823</td>\n",
       "      <td>3.112398</td>\n",
       "      <td>-0.223342</td>\n",
       "      <td>0.743935</td>\n",
       "      <td>-0.169637</td>\n",
       "      <td>0.997423</td>\n",
       "      <td>-0.383258</td>\n",
       "      <td>1.390824</td>\n",
       "      <td>-0.539686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.939789</td>\n",
       "      <td>-0.830841</td>\n",
       "      <td>-1.519486</td>\n",
       "      <td>-0.321296</td>\n",
       "      <td>-0.223342</td>\n",
       "      <td>-1.344203</td>\n",
       "      <td>-0.169637</td>\n",
       "      <td>0.997423</td>\n",
       "      <td>0.148621</td>\n",
       "      <td>-1.436520</td>\n",
       "      <td>1.286407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.959423</td>\n",
       "      <td>-0.830841</td>\n",
       "      <td>1.233697</td>\n",
       "      <td>-0.321296</td>\n",
       "      <td>-0.223342</td>\n",
       "      <td>0.743935</td>\n",
       "      <td>-0.169637</td>\n",
       "      <td>-1.002584</td>\n",
       "      <td>-0.822123</td>\n",
       "      <td>0.958869</td>\n",
       "      <td>-1.452733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.465542</td>\n",
       "      <td>1.201081</td>\n",
       "      <td>-1.253049</td>\n",
       "      <td>-0.321296</td>\n",
       "      <td>-0.223342</td>\n",
       "      <td>-1.344203</td>\n",
       "      <td>-1.084428</td>\n",
       "      <td>-1.002584</td>\n",
       "      <td>1.317458</td>\n",
       "      <td>-1.240176</td>\n",
       "      <td>1.286407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.193108</td>\n",
       "      <td>-0.830841</td>\n",
       "      <td>0.212355</td>\n",
       "      <td>-0.321296</td>\n",
       "      <td>-0.223342</td>\n",
       "      <td>0.743935</td>\n",
       "      <td>-0.169637</td>\n",
       "      <td>0.997423</td>\n",
       "      <td>2.469593</td>\n",
       "      <td>2.817585</td>\n",
       "      <td>1.286407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.781793</td>\n",
       "      <td>-0.830841</td>\n",
       "      <td>0.434386</td>\n",
       "      <td>-0.321296</td>\n",
       "      <td>-0.223342</td>\n",
       "      <td>0.743935</td>\n",
       "      <td>-0.169637</td>\n",
       "      <td>0.997423</td>\n",
       "      <td>-0.623799</td>\n",
       "      <td>-1.423430</td>\n",
       "      <td>-1.452733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.241405</td>\n",
       "      <td>-0.830841</td>\n",
       "      <td>1.455728</td>\n",
       "      <td>-0.321296</td>\n",
       "      <td>4.477446</td>\n",
       "      <td>0.743935</td>\n",
       "      <td>0.745154</td>\n",
       "      <td>-1.002584</td>\n",
       "      <td>3.225312</td>\n",
       "      <td>-0.206102</td>\n",
       "      <td>-0.539686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.999442</td>\n",
       "      <td>-0.830841</td>\n",
       "      <td>-0.453738</td>\n",
       "      <td>-0.321296</td>\n",
       "      <td>-0.223342</td>\n",
       "      <td>0.743935</td>\n",
       "      <td>-0.169637</td>\n",
       "      <td>-1.002584</td>\n",
       "      <td>-0.621943</td>\n",
       "      <td>0.487645</td>\n",
       "      <td>0.373360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.363145</td>\n",
       "      <td>-0.830841</td>\n",
       "      <td>1.411322</td>\n",
       "      <td>3.112398</td>\n",
       "      <td>-0.223342</td>\n",
       "      <td>0.743935</td>\n",
       "      <td>0.745154</td>\n",
       "      <td>0.997423</td>\n",
       "      <td>2.351062</td>\n",
       "      <td>3.406615</td>\n",
       "      <td>-0.539686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id    gender       age  hypertension  heart_disease  ever_married  \\\n",
       "0 -0.268469  1.201081 -1.741517     -0.321296      -0.223342     -1.344203   \n",
       "1 -0.278007  1.201081  0.700823      3.112398      -0.223342      0.743935   \n",
       "2 -0.939789 -0.830841 -1.519486     -0.321296      -0.223342     -1.344203   \n",
       "3  0.959423 -0.830841  1.233697     -0.321296      -0.223342      0.743935   \n",
       "4  0.465542  1.201081 -1.253049     -0.321296      -0.223342     -1.344203   \n",
       "5 -0.193108 -0.830841  0.212355     -0.321296      -0.223342      0.743935   \n",
       "6  0.781793 -0.830841  0.434386     -0.321296      -0.223342      0.743935   \n",
       "7  0.241405 -0.830841  1.455728     -0.321296       4.477446      0.743935   \n",
       "8 -0.999442 -0.830841 -0.453738     -0.321296      -0.223342      0.743935   \n",
       "9 -0.363145 -0.830841  1.411322      3.112398      -0.223342      0.743935   \n",
       "\n",
       "   work_type  Residence_type  avg_glucose_level       bmi  smoking_status  \n",
       "0   1.659945       -1.002584          -0.217176 -1.384161        1.286407  \n",
       "1  -0.169637        0.997423          -0.383258  1.390824       -0.539686  \n",
       "2  -0.169637        0.997423           0.148621 -1.436520        1.286407  \n",
       "3  -0.169637       -1.002584          -0.822123  0.958869       -1.452733  \n",
       "4  -1.084428       -1.002584           1.317458 -1.240176        1.286407  \n",
       "5  -0.169637        0.997423           2.469593  2.817585        1.286407  \n",
       "6  -0.169637        0.997423          -0.623799 -1.423430       -1.452733  \n",
       "7   0.745154       -1.002584           3.225312 -0.206102       -0.539686  \n",
       "8  -0.169637       -1.002584          -0.621943  0.487645        0.373360  \n",
       "9   0.745154        0.997423           2.351062  3.406615       -0.539686  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "motivated-glenn",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43400,)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y= data['stroke']\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "particular-endorsement",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=.3, random_state = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "italic-bernard",
   "metadata": {},
   "outputs": [],
   "source": [
    "log= LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "marine-moldova",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaged-companion",
   "metadata": {},
   "source": [
    "## Class weights in Logistic Regression\n",
    "\n",
    "We can modify every machine learning algorithm by adding different class weights to the cost function of the algorithm, but here we will specifically focus on logistic regression.\n",
    "\n",
    "For the logistic regression, we use log loss as the cost function. We don’t use the mean squared error as the cost function for the logistic regression because instead of fitting a straight line, we use the sigmoid curve as the prediction function. Squaring the sigmoid function will result in a non-convex curve due to which the cost function will have a lot of local minima and converging to the global minima using gradient descent is extremely difficult. But log loss forms a convex function, and we only have one minimum to converge.\n",
    "\n",
    "The formula for log loss:\n",
    "\n",
    "$$\n",
    "log~loss = \\frac{1}{N}\\sum_{i=1}^{N}\\Big{(}-(y_i\\log(\\hat{y}_i)+(1-y_i)\\log(1-\\hat{y}_i)) \\Big{)}\n",
    "$$\n",
    "\n",
    "\n",
    "Here,\n",
    "\n",
    "- N is the number of values\n",
    "- yi is the actual value of the target class\n",
    "- yi is the predicted probability of the target class\n",
    "\n",
    "Let’s form a pseudo table that has actual predictions, predicted probabilities, and calculated cost using the log loss formula:\n",
    "\n",
    "|Actual Value|Predicted Prob.(class 1)|Penalty Cost|\n",
    "|:-:|:-:|:-:|\n",
    "|0|0.32|0.385|\n",
    "|0|0.18|0.198|\n",
    "|0|0.28|0.328|\n",
    "|0|0.12|0.127|\n",
    "|0|0.08|0.083|\n",
    "|**1**|**0.44**|**0.82**|\n",
    "|0|0.24|0.274|\n",
    "|0|0.01|0.01|\n",
    "|0|0.22|0.248|\n",
    "|0|0.16|0.174|\n",
    "\n",
    "In this table, we have ten observations with nine observations from class 0 and 1 from class 1. In the next column, we have the predicted probabilities for each observation. And finally, using the log loss formula, we have the cost penalty.\n",
    "\n",
    "After adding the weights to the cost function, the modified log loss function is:\n",
    "\n",
    "$$\n",
    "log~loss = \\frac{1}{N}\\sum_{i=1}^{N}\\Big{(}-(w_0y_i\\log(\\hat{y}_i)+w_1(1-y_i)\\log(1-\\hat{y}_i)) \\Big{)}\n",
    "$$\n",
    "\n",
    "Here,\n",
    "\n",
    "- w0 is the class weight for class 0\n",
    "- w1 is the class weight for class 1\n",
    "\n",
    "Now, we will add the weights and see what difference will it make to the cost penalty.\n",
    "\n",
    "For the values of the weights, we will be using the class_weights=’balanced’ formula.\n",
    "\n",
    "w0= 10/(2*1) = 5\n",
    "\n",
    "w1= 10/(2*9) = 0.55\n",
    "\n",
    "Calculating the cost for the first value in the table:\n",
    "\n",
    "Cost = -(5(0*log(0.32) + 0.55(1-0)*log(1-0.32))\n",
    "\n",
    "= -(0 + 0.55*log(.68))\n",
    "\n",
    "= -(0.55*(-0.385))\n",
    "\n",
    "= 0.211\n",
    "\n",
    "Similarly, we can calculate the weighted cost for each observation, and the updated table is:\n",
    "\n",
    "|Actual Value|Predicted Prob.(class 1)|Penalty Cost|\n",
    "|:-:|:-:|:-:|\n",
    "|0|0.32|0.211|\n",
    "|0|0.18|0.109|\n",
    "|0|0.28|0.18|\n",
    "|0|0.12|0.069|\n",
    "|0|0.08|0.045|\n",
    "|**1**|**0.48**|**4.104**|\n",
    "|0|0.24|0.15|\n",
    "|0|0.01|0.005|\n",
    "|0|0.22|0.136|\n",
    "|0|0.16|0.095|\n",
    "\n",
    "Through the table, we can confirm the small weight applied to the cost function for the majority class that results in a smaller error value, and in turn, less update to the model coefficients. A more considerable weight value applied to the cost function for the minority class that results in a larger error calculation, and in turn, more updates to the model coefficients. This way, we can shift the bias of the model so that it could also reduce the errors of the minority class.\n",
    "\n",
    " \n",
    "\n",
    "**Conclusion:**\n",
    "\n",
    "- Small weights result in a small penalty and a small update to the model coefficients\n",
    "- Large weights result in a large penalty and a large update to the model coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "excess-twist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9822580645161291"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the accuracy has dropped\n",
    "log.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bridal-harris",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting the output with Logistic\n",
    "pred_train= log.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "likely-queensland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for mode model is: 0.9812596006144393\n",
      "The f1 score for the mode model is: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[12776,     0],\n",
       "       [  244,     0]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training the model using mode of target\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
    "pred_test= log.predict(X_test)\n",
    "\n",
    "#Printing f1 and accuracy scores    \n",
    "print('The accuracy for mode model is:', accuracy_score(y_test, pred_test))\n",
    "print('The f1 score for the mode model is:',f1_score(y_test, pred_test))\n",
    "\n",
    "#Ploting the cunfusion matrix\n",
    "confusion_matrix(y_test, pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funded-hampton",
   "metadata": {},
   "source": [
    "The accuracy for the mode model is: **0.9819508448540707**\n",
    "\n",
    "The f1 score for the mode model is: **0.0**\n",
    "\n",
    "Here, the accuracy of the mode model on the testing data is 0.98 which is an excellent score. But on the other hand, the f1 score is zero which indicates that the model is performing poorly on the minority class. We can confirm this by looking at the confusion matrix.\n",
    "\n",
    "The mode model is predicting every patient as 0 (no heart stroke). According to this model, no matter what the symptoms a patient has, he/she will never have a heart stroke. Does using this model makes any sense?\n",
    "\n",
    "Now that we got the gist of what is class imbalance and how it plagues our model performance, we will shift our focus to what class weights are and how class weights can help in improving the model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "later-administration",
   "metadata": {},
   "source": [
    "## What are the class weights?\n",
    "\n",
    "Most machine learning algorithms are not very useful with biased class data. But, we can modify the current training algorithm to take into account the skewed distribution of the classes. This can be achieved by giving different weights to both the majority and minority classes. The difference in weights will influence the classification of the classes during the training phase. The whole purpose is to penalize the misclassification made by the minority class by setting a higher class weight and at the same time reducing weight for the majority class.\n",
    "\n",
    "To make this a bit clear, we will be reviving the city example we considered earlier.\n",
    "\n",
    "Please think of it this way that the last month you have spent in the new city, instead of going out when it is needed, you spent the whole month exploring the city. You spent more time understanding the city routes and places the entire month. Giving more time to research will help you to understand the new city better, and the chances of getting lost will reduce. And this is precisely how class weights work. During the training, we give more weightage to the minority class in the cost function of the algorithm so that it could provide a higher penalty to the minority class and the algorithm could focus on reducing the errors for the minority class.\n",
    "\n",
    "**Note:** *There is a threshold to which you should increase and decrease the class weights for the minority and majority class respectively. If you give very high-class weights to the minority class, chances are the algorithm will get biased towards the minority class, and it will increase the errors in the majority class.*\n",
    "\n",
    "Most of the sklearn classifier modeling libraries and even some boosting based libraries like LightGBM and catboost have an in-built parameter “class_weight” which helps us optimize the scoring for the minority class just the way we have learned so far.\n",
    "\n",
    "By default, the value of class_weight=None, i.e. both the classes have been given equal weights. Other than that, we can either give it as ‘balanced’ or we can pass a dictionary that contains manual weights for both the classes.\n",
    "\n",
    "When the class_weights = ‘balanced’, the model automatically assigns the class weights inversely proportional to their respective frequencies.\n",
    "\n",
    "To be more precise, the formula to calculate this is:\n",
    "\n",
    "$$\n",
    "wj=\\frac{n\\_samples}{(n\\_classes * n\\_samplesj)}\n",
    "$$\n",
    "\n",
    "Here,\n",
    "\n",
    "- wj is the weight for each class(j signifies the class)\n",
    "- n_samples is the total number of samples or rows in the dataset\n",
    "- n_classes is the total number of unique classes in the target\n",
    "- n_samplesj is the total number of rows of the respective class\n",
    "\n",
    "For our heart stroke example:\n",
    "\n",
    "n_samples=  43400,  n_classes= 2(0&1), n_sample0= 42617, n_samples1= 783\n",
    "\n",
    "Weights for class 0:\n",
    "\n",
    "w0=  43400/(2*42617) = 0.509\n",
    "\n",
    "Weights for class 1:\n",
    "\n",
    "w1= 43400/(2*783) = 27.713\n",
    "\n",
    "I hope this makes things more clear that how class_weight = ‘balanced’ helps us to in giving higher weights to the minority class and lower weights to the majority class.\n",
    "\n",
    "Although passing value as ‘balanced’ gives good results in most cases but sometimes for extreme class imbalance, we can try giving weights manually. Later we will see how we can find the optimal value for the class weights in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driving-junior",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
