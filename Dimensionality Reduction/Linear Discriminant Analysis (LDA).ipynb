{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "framed-snapshot",
   "metadata": {},
   "source": [
    "# Linear Discriminant Analysis (LDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applied-singer",
   "metadata": {},
   "source": [
    "## What is LDA\n",
    "\n",
    "(Fishers) Linear Discriminant Analysis (LDA) searches for the projection of a dataset which maximizes the *between class scatter to within class scatter* ($\\frac{S_B}{S_W}$) ratio of this projected dataset. The goal is to project/transform a dataset $A$ using a transformation matrix $w$ such that the ratio of between class scatter to within class scatter of the transformed dataset $y=w^T*A$\n",
    " is maximized. Hence our goal is to find the transformation matrix  that accomplishes this. In Fisher's terms:\n",
    "*\"Find the linear combination $Z=a^T*X$ such that the between class variance is maximized relative to the within class variance.\"*(Hastie, Tibshirani and Friedman, 2008, p.114). Therewith, LDA is like PCA which we have introduced in the last chapter with the difference, that LDA aims to find the projection of maximum separability. But slowly. Consider the following illustration which shows a dataset consisting of three different classes. We now want to have the within and between class scatter of this dataset.\n",
    "\n",
    "![LDA](./images/LDA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broad-satellite",
   "metadata": {},
   "source": [
    "## Maths behind LDA\n",
    "\n",
    "As we can see in the illustration, we want to have a measure of the within and between class scatters. Therefore, we use the following two formulas for the between class scatter $S_B$ and the within class scatter $S_w$. Let's derive the meaning of them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affiliated-snake",
   "metadata": {},
   "source": [
    "### 1. Scatter Within ($S_w$)\n",
    "$$\n",
    "S_w= \\sum_{classes~c}\\sum_{j\\in c}(x_j-\\mu_c)(x_j-\\mu_c)^T\n",
    "$$\n",
    "where\n",
    "- $classes~c$ are different classes \n",
    "- $x_j$ is the value vector per instance per class\n",
    "- $\\mu_c$ represents the mean-vector of class $c$ and is a vector which contains the values of each dimension for each class\n",
    "\n",
    "Mind that we calculated the scatter matrices and not the covariance matrices since then we must divide by n respectively n-1 but we didn't do that here. Nevertheless, the dimensionality of the scatter matrix is the same as for the covariance matrix. When a class has 2 dimensions, the scatter matrix is of shape (2x2) and consists of the elements:\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "scatter_{xx} & scatter_{xy} \\\\\n",
    "scatter_{yx} & scatter_{yy}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "As said, we calculate the scatter per class and then sum up all the per_class scatter matrices to receive a measure for the scatter within ($S_w$)\n",
    "\n",
    "Let's derive this with Python code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "reserved-german",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.07646534 -0.05208045]\n",
      " [-0.05208045  0.45007299]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "style.use('fivethirtyeight')\n",
    "np.random.seed(seed=42)\n",
    "\n",
    "# Create data\n",
    "rectangles = np.array([[1,1.5,1.7,1.45,1.1,1.6,1.8],[1.8,1.55,1.45,1.6,1.65,1.7,1.75]])\n",
    "triangles = np.array([[0.1,0.5,0.25,0.4,0.3,0.6,0.35,0.15,0.4,0.5,0.48],[1.1,1.5,1.3,1.2,1.15,1.0,1.4,1.2,1.3,1.5,1.0]])\n",
    "circles = np.array([[1.5,1.55,1.52,1.4,1.3,1.6,1.35,1.45,1.4,1.5,1.48,1.51,1.52,1.49,1.41,1.39,1.6,1.35,1.55,1.47,1.57,1.48,\n",
    "                    1.55,1.555,1.525,1.45,1.35,1.65,1.355,1.455,1.45,1.55,1.485,1.515,1.525,1.495,1.415,1.395,1.65,1.355,1.555,1.475,1.575,1.485]\n",
    "                    ,[1.3,1.35,1.33,1.32,1.315,1.30,1.34,1.32,1.33,1.35,1.30,1.31,1.35,1.33,1.32,1.315,1.38,1.34,1.28,1.23,1.25,1.29,\n",
    "                     1.35,1.355,1.335,1.325,1.3155,1.305,1.345,1.325,1.335,1.355,1.305,1.315,1.355,1.335,1.325,1.3155,1.385,1.345,1.285,1.235,1.255,1.295]])\n",
    "\n",
    "#Plot the data\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax0 = fig.add_subplot(111)\n",
    "\n",
    "ax0.scatter(rectangles[0],rectangles[1],marker='s',c='grey',edgecolor='black')\n",
    "ax0.scatter(triangles[0],triangles[1],marker='^',c='yellow',edgecolor='black')\n",
    "ax0.scatter(circles[0],circles[1],marker='o',c='blue',edgecolor='black')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calculate the mean vectors per class\n",
    "mean_rectangles = np.mean(rectangles,axis=1).reshape(2,1) # Creates a 2x1 vector consisting of the means of the dimensions \n",
    "mean_triangles = np.mean(triangles,axis=1).reshape(2,1)\n",
    "mean_circles = np.mean(circles,axis=1).reshape(2,1)\n",
    "\n",
    "# Calculate the scatter matrices for the SW (Scatter within) and sum the elements up\n",
    "\n",
    "scatter_rectangles = np.dot((rectangles-mean_rectangles),(rectangles-mean_rectangles).T)\n",
    "\n",
    "\n",
    "# Mind that we do not calculate the covariance matrix here because then we have to divide by n or n-1 as shown below\n",
    "#print((1/7)*np.dot((rectangles-mean_rectangles),(rectangles-mean_rectangles).T))\n",
    "#print(np.var(rectangles[0],ddof=0))\n",
    "\n",
    "scatter_triangles = np.dot((triangles-mean_triangles),(triangles-mean_triangles).T)\n",
    "scatter_circles = np.dot((circles-mean_circles),(circles-mean_circles).T)\n",
    "\n",
    "# Calculate the SW by adding the scatters within classes \n",
    "SW = scatter_triangles+scatter_circles+scatter_rectangles\n",
    "print(SW)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "temporal-viking",
   "metadata": {},
   "source": [
    "## Scatter Between ($S_B$)\n",
    "\n",
    "$$\n",
    "S_B= \\sum_{classes~c}N_c(\\mu_c-\\mu)(\\mu_c-\\mu)^T\n",
    "$$\n",
    "\n",
    "With this second formula figuratively speaking, we measure the scatter of the total dataset, that is the scatter between the classes and therewith how \"far away\" the single class-clusters are. Here $classes~c$ are the different classes of our dataset (rectangles, triangles, circles). $\\mu_c$ is the mean per class. $\\mu$ is the mean of the total dataset and contains one value per dimension with the difference that we now consider all datapoints in the dataset and not only the datapoints belonging to one class $c$. The derivation of the $S_B$ is not that obvious and the details can be find [here](https://www.python-course.eu/linear_discriminant_analysis.php)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viral-conditions",
   "metadata": {},
   "source": [
    "We can summariz the process of obtaining $w$ which is used to transform our original dataset, in six steps:\n",
    "\n",
    "1. Standardize the dataset (zero mean, standard deviation of 1)\n",
    "2. Compute the total mean vector $\\mu$ as well as the mean vectors per class $\\mu_c$ \n",
    "3. Compute the scatter withing and scatter between matrices $S_B$ and $S_W$ \n",
    "4. Compute the eigenvalues and eigenvectors of $S_W^{-1}S_B$ to find the $w$ which maximizes $\\frac{w^TS_Bw}{w^TS_Ww}$ \n",
    "5. Select the Eigenvectors of the corresponding $k$ largest Eigenvalues to create a $d\\times k$ dimensional transformation matrix $w$ where the Eigenvectors are the columns of this matrix\n",
    "6. Use $w$ to transform the original $n\\times d$ dimensional dataset $x$ into a lower, $n\\times k$ dimensional dataset $y$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valued-indication",
   "metadata": {},
   "source": [
    "## LDA with sklearn\n",
    "\n",
    "The Linear Discriminant Analysis is available in the scikit-learn Python machine learning library via the [LinearDiscriminantAnalysis class](https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html).\n",
    "\n",
    "The method can be used directly without configuration, although the implementation does offer arguments for customization, such as the choice of solver and the use of a penalty.\n",
    "\n",
    "```python\n",
    "...\n",
    "# create the lda model\n",
    "model = LinearDiscriminantAnalysis()\n",
    "```\n",
    "\n",
    "We can demonstrate the Linear Discriminant Analysis method with a worked example.\n",
    "\n",
    "First, let’s define a synthetic classification dataset.\n",
    "\n",
    "We will use the [`make_classification()` function](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html) to create a dataset with 1,000 examples, each with 10 input variables.\n",
    "\n",
    "The example creates and summarizes the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "identified-degree",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 10) (1000,)\n"
     ]
    }
   ],
   "source": [
    "# test classification dataset\n",
    "from sklearn.datasets import make_classification\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=10, n_redundant=0, random_state=1)\n",
    "# summarize the dataset\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resistant-edgar",
   "metadata": {},
   "source": [
    "Running the example creates the dataset and confirms the number of rows and columns of the dataset.\n",
    "\n",
    "We can fit and evaluate a Linear Discriminant Analysis model using [repeated stratified k-fold cross-validation](https://machinelearningmastery.com/k-fold-cross-validation/) via the [RepeatedStratifiedKFold class](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RepeatedStratifiedKFold.html). We will use 10 folds and three repeats in the test harness.\n",
    "\n",
    "The complete example of evaluating the Linear Discriminant Analysis model for the synthetic binary classification task is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "widespread-involvement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.893 (0.033)\n"
     ]
    }
   ],
   "source": [
    "# evaluate a lda model on the dataset\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=10, n_redundant=0, random_state=1)\n",
    "# define model\n",
    "model = LinearDiscriminantAnalysis()\n",
    "# define model evaluation method\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# summarize result\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automatic-geography",
   "metadata": {},
   "source": [
    "Running the example evaluates the Linear Discriminant Analysis algorithm on the synthetic dataset and reports the average accuracy across the three repeats of 10-fold cross-validation.\n",
    "\n",
    "Your specific results may vary given the stochastic nature of the learning algorithm. Consider running the example a few times.\n",
    "\n",
    "In this case, we can see that the model achieved a mean accuracy of about 89.3 percent.\n",
    "\n",
    "We may decide to use the Linear Discriminant Analysis as our final model and make predictions on new data.\n",
    "\n",
    "This can be achieved by fitting the model on all available data and calling the `predict()` function passing in a new row of data.\n",
    "\n",
    "We can demonstrate this with a complete example listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "inside-cattle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: 1\n"
     ]
    }
   ],
   "source": [
    "# make a prediction with a lda model on the dataset\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=10, n_redundant=0, random_state=1)\n",
    "# define model\n",
    "model = LinearDiscriminantAnalysis()\n",
    "# fit model\n",
    "model.fit(X, y)\n",
    "# define new data\n",
    "row = [0.12777556,-3.64400522,-2.23268854,-1.82114386,1.75466361,0.1243966,1.03397657,2.35822076,1.01001752,0.56768485]\n",
    "# make a prediction\n",
    "yhat = model.predict([row])\n",
    "# summarize prediction\n",
    "print('Predicted Class: %d' % yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threatened-damage",
   "metadata": {},
   "source": [
    "Running the example fits the model and makes a class label prediction for a new row of data.\n",
    "\n",
    "Next, we can look at configuring the model hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verbal-treasury",
   "metadata": {},
   "source": [
    "## Tune LDA Hyperparameters\n",
    "\n",
    "The hyperparameters for the Linear Discriminant Analysis method must be configured for your specific dataset.\n",
    "\n",
    "An important hyperparameter is the solver, which defaults to ‘svd‘ but can also be set to other values for solvers that support the shrinkage capability.\n",
    "\n",
    "The example below demonstrates this using the [GridSearchCV class](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) with a grid of different solver values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "useful-farming",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.893\n",
      "Config: {'solver': 'svd'}\n"
     ]
    }
   ],
   "source": [
    "# grid search solver for lda\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=10, n_redundant=0, random_state=1)\n",
    "# define model\n",
    "model = LinearDiscriminantAnalysis()\n",
    "# define model evaluation method\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# define grid\n",
    "grid = dict()\n",
    "grid['solver'] = ['svd', 'lsqr', 'eigen']\n",
    "# define search\n",
    "search = GridSearchCV(model, grid, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# perform the search\n",
    "results = search.fit(X, y)\n",
    "# summarize\n",
    "print('Mean Accuracy: %.3f' % results.best_score_)\n",
    "print('Config: %s' % results.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secure-desperate",
   "metadata": {},
   "source": [
    "Running the example will evaluate each combination of configurations using repeated cross-validation.\n",
    "\n",
    "Your specific results may vary given the stochastic nature of the learning algorithm. Try running the example a few times.\n",
    "\n",
    "In this case, we can see that the default SVD solver performs the best compared to the other built-in solvers.\n",
    "\n",
    "Next, we can explore whether using shrinkage with the model improves performance.\n",
    "\n",
    "Shrinkage adds a penalty to the model that acts as a type of regularizer, reducing the complexity of the model.\n",
    "\n",
    "> Regularization reduces the variance associated with the sample based estimate at the expense of potentially increased bias. This bias variance trade-off is generally regulated by one or more (degree-of-belief) parameters that control the strength of the biasing towards the “plausible” set of (population) parameter values.\n",
    "\n",
    "This can be set via the “shrinkage” argument and can be set to a value between 0 and 1. We will test values on a grid with a spacing of 0.01.\n",
    "\n",
    "In order to use the penalty, a solver must be chosen that supports this capability, such as ‘eigen’ or ‘lsqr‘. We will use the latter in this case.\n",
    "\n",
    "The complete example of tuning the shrinkage hyperparameter is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "pregnant-external",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.894\n",
      "Config: {'shrinkage': 0.02}\n"
     ]
    }
   ],
   "source": [
    "# grid search shrinkage for lda\n",
    "from numpy import arange\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=10, n_redundant=0, random_state=1)\n",
    "# define model\n",
    "model = LinearDiscriminantAnalysis(solver='lsqr')\n",
    "# define model evaluation method\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# define grid\n",
    "grid = dict()\n",
    "grid['shrinkage'] = arange(0, 1, 0.01)\n",
    "# define search\n",
    "search = GridSearchCV(model, grid, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# perform the search\n",
    "results = search.fit(X, y)\n",
    "# summarize\n",
    "print('Mean Accuracy: %.3f' % results.best_score_)\n",
    "print('Config: %s' % results.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scientific-translation",
   "metadata": {},
   "source": [
    "Running the example will evaluate each combination of configurations using repeated cross-validation.\n",
    "\n",
    "Your specific results may vary given the stochastic nature of the learning algorithm. Try running the example a few times.\n",
    "\n",
    "In this case, we can see that using shrinkage offers a slight lift in performance from about 89.3 percent to about 89.4 percent, with a value of 0.02."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "physical-investigation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
